{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZjFpHnEtIR7YXnXaAZBRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mozhi193/Thenmozhi---Women-s-call-thing-recommended/blob/main/Women's_clothing_recommended.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7b1Dp6Q0yl9"
      },
      "outputs": [],
      "source": [
        "Import library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "Import Dataset\n",
        "\n",
        "df=pd.read_csv('https://github.com/NadimKawwa/WomeneCommerce/raw/master/Womens%20Clothing%20E-Commerce%20Reviews.csv')\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n",
        "Unnamed: 0  Clothing ID Age Title   Review Text Rating  Recommended IND Positive Feedback Count Division Name   Department Name Class Name\n",
        "0   0   767 33  NaN Absolutely wonderful - silky and sexy and comf...   4   1   0   Initmates   Intimate    Intimates\n",
        "1   1   1080    34  NaN Love this dress! it's sooo pretty. i happene... 5   1   4   General Dresses Dresses\n",
        "2   2   1077    60  Some major design flaws I had such high hopes for this dress and reall...   3   0   0   General Dresses Dresses\n",
        "3   3   1049    50  My favorite buy!    I love, love, love this jumpsuit. it's fun, fl...   5   1   0   General Petite  Bottoms Pants\n",
        "4   4   847 47  Flattering shirt    This shirt is very flattering to all due to th...   5   1   6   General Tops    Blouses\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 23486 entries, 0 to 23485\n",
        "Data columns (total 11 columns):\n",
        " #   Column                   Non-Null Count  Dtype\n",
        "---  ------                   --------------  -----\n",
        " 0   Unnamed: 0               23486 non-null  int64\n",
        " 1   Clothing ID              23486 non-null  int64\n",
        " 2   Age                      23486 non-null  int64\n",
        " 3   Title                    19676 non-null  object\n",
        " 4   Review Text              22641 non-null  object\n",
        " 5   Rating                   23486 non-null  int64\n",
        " 6   Recommended IND          23486 non-null  int64\n",
        " 7   Positive Feedback Count  23486 non-null  int64\n",
        " 8   Division Name            23472 non-null  object\n",
        " 9   Department Name          23472 non-null  object\n",
        " 10  Class Name               23472 non-null  object\n",
        "dtypes: int64(6), object(5)\n",
        "memory usage: 2.0+ MB\n",
        "\n",
        "df.shape\n",
        "\n",
        "(23486, 11)\n",
        "Missing values\n",
        "Removing missing values in Reviews columns with Review text\n",
        "\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "Unnamed: 0                    0\n",
        "Clothing ID                   0\n",
        "Age                           0\n",
        "Title                      3810\n",
        "Review Text                 845\n",
        "Rating                        0\n",
        "Recommended IND               0\n",
        "Positive Feedback Count       0\n",
        "Division Name                14\n",
        "Department Name              14\n",
        "Class Name                   14\n",
        "dtype: int64\n",
        "\n",
        "df[df['Review Text']==\"\"]=np.NaN\n",
        "\n",
        "\n",
        "df['Review Text'].fillna(\"No Review\",inplace=True)\n",
        "\n",
        "Define Target (y) and Feature (X)\n",
        "\n",
        "df.columns\n",
        "\n",
        "Index(['Unnamed: 0', 'Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
        "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
        "       'Department Name', 'Class Name'],\n",
        "      dtype='object')\n",
        "\n",
        "x=df['Review Text']\n",
        "\n",
        "\n",
        "y=df['Rating']\n",
        "\n",
        "\n",
        "df['Rating'].value_counts()\n",
        "\n",
        "5.0    13131\n",
        "4.0     5077\n",
        "3.0     2871\n",
        "2.0     1565\n",
        "1.0      842\n",
        "Name: Rating, dtype: int64\n",
        "Train Test Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,train_size=0.7, stratify=y, random_state=2529)\n",
        "\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "((16440,), (7046,), (16440,), (7046,))\n",
        "Get Future text Conversion to Tokens\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "cv=CountVectorizer(lowercase =True, analyzer = 'word', ngram_range=(2,3),stop_words=\"english\", max_features=5000)\n",
        "\n",
        "\n",
        "X_train=cv.fit_transform(X_train)\n",
        "\n",
        "\n",
        "cv.get_feature_names_out()\n",
        "\n",
        "array(['10 12', '10 bought', '10 fit', ..., 'yellow color', 'yoga pants',\n",
        "       'zipper little'], dtype=object)\n",
        "\n",
        "X_train.toarray()\n",
        "\n",
        "array([[0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       ...,\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0]])\n",
        "\n",
        "X_test = cv.fit_transform(X_test)\n",
        "\n",
        "\n",
        "cv.get_feature_names_out()\n",
        "\n",
        "array(['10 12', '10 dress', '10 fit', ..., 'years come', 'years old',\n",
        "       'yoga pants'], dtype=object)\n",
        "\n",
        "X_test.toarray()\n",
        "\n",
        "array([[0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       ...,\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0]])\n",
        "get Model Train\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "model= MultinomialNB()\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "MultinomialNB()\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "Get Model Prediction\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred.shape\n",
        "\n",
        "(7046,)\n",
        "\n",
        "y_pred\n",
        "\n",
        "array([1., 5., 5., ..., 5., 5., 5.])\n",
        "Get Probabiltity of each Predicted Class\n",
        "\n",
        "model.predict_proba(X_test)\n",
        "\n",
        "array([[0.71118473, 0.02625165, 0.15465118, 0.01496876, 0.09294369],\n",
        "       [0.02416867, 0.04769471, 0.35268622, 0.16185007, 0.41360034],\n",
        "       [0.03582725, 0.06660584, 0.12226277, 0.21618005, 0.55912409],\n",
        "       ...,\n",
        "       [0.02320281, 0.08950939, 0.08962183, 0.16719203, 0.63047394],\n",
        "       [0.01167675, 0.00202714, 0.08539004, 0.34347398, 0.55743209],\n",
        "       [0.03959824, 0.05612822, 0.00688869, 0.1560574 , 0.74132745]])\n",
        "Get Model Evaluation\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "[[  15   13   45   36  144]\n",
        " [  43   43   86   85  213]\n",
        " [ 116   78  113  166  388]\n",
        " [ 166  108  194  336  719]\n",
        " [ 371  272  349  722 2225]]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         1.0       0.02      0.06      0.03       253\n",
        "         2.0       0.08      0.09      0.09       470\n",
        "         3.0       0.14      0.13      0.14       861\n",
        "         4.0       0.25      0.22      0.23      1523\n",
        "         5.0       0.60      0.56      0.58      3939\n",
        "\n",
        "    accuracy                           0.39      7046\n",
        "   macro avg       0.22      0.21      0.21      7046\n",
        "weighted avg       0.42      0.39      0.40      7046\n",
        "\n",
        "Recategories Ratings as poor (0) and Good (1)\n",
        "\n",
        "df['Rating'].value_counts()\n",
        "\n",
        "5.0    13131\n",
        "4.0     5077\n",
        "3.0     2871\n",
        "2.0     1565\n",
        "1.0      842\n",
        "Name: Rating, dtype: int64\n",
        "Re-Rating as 1,2,3 as 0 and 4,5 as 1\n",
        "\n",
        "\n",
        "df.replace({'Rating': { 1: 0, 2:0, 3:0, 4:1, 5:1}}, inplace=True)\n",
        "\n",
        "\n",
        "y=df['Rating']\n",
        "\n",
        "\n",
        "X=df['Review Text']\n",
        "\n",
        "Train Test Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size = 0.7, stratify =y, random_state=2529)\n",
        "\n",
        "\n",
        "X_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "\n",
        "((16440,), (7046,), (7046,))\n",
        "get Feature Text conversion to Tokens\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "cv=CountVectorizer(lowercase=True, analyzer ='word', ngram_range=(2,3), stop_words='english', max_features=5000)\n",
        "\n",
        "\n",
        "X_train = cv.fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test =cv.fit_transform(X_test)\n",
        "\n",
        "Get Model Re-Train\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "model=MultinomialNB()\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "MultinomialNB()\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "Get model Prediction\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred.shape\n",
        "\n",
        "(7046,)\n",
        "\n",
        "y_pred\n",
        "\n",
        "array([1., 1., 1., ..., 1., 1., 1.])\n",
        "get model evaluation\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "[[ 449 1134]\n",
        " [ 989 4474]]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.31      0.28      0.30      1583\n",
        "         1.0       0.80      0.82      0.81      5463\n",
        "\n",
        "    accuracy                           0.70      7046\n",
        "   macro avg       0.56      0.55      0.55      7046\n",
        "weighted avg       0.69      0.70      0.69      7046\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.31      0.28      0.30      1583\n",
        "         1.0       0.80      0.82      0.81      5463\n",
        "\n",
        "    accuracy                           0.70      7046\n",
        "   macro avg       0.56      0.55      0.55      7046\n",
        "weighted avg       0.69      0.70      0.69      7046"
      ]
    }
  ]
}